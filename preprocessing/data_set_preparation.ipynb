{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsp/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from preprocessing.data_preparation import read_data\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# merge items and train data to a dataFrame\n",
    "def merge_data(input_path, items_path, output_path):\n",
    "    tdf = read_data(input_path)\n",
    "    idf = read_data(items_path)\n",
    "    print('data read successfully!')\n",
    "    output = Path(output_path)\n",
    "    if not output.is_file():\n",
    "        train_merged = tdf.copy()\n",
    "        train_merged = train_merged.merge(tdf.merge(idf, how='left', on='pid', sort=False))\n",
    "        pd.to_pickle(train_merged, output_path)\n",
    "        return train_merged\n",
    "    else:\n",
    "        return pd.read_pickle(output_path)\n",
    "\n",
    "\n",
    "def extract_numbers_from_content(input):\n",
    "    x_index = input.find('X')\n",
    "    if input == 'L   125':\n",
    "        return 1, 1, 125\n",
    "    if x_index == -1:\n",
    "        if input == 'PAK':\n",
    "            return 1, 1, 1\n",
    "        return 1, 1, input\n",
    "    second_part = input[x_index + 1: len(input)]\n",
    "    x_second_index = second_part.find('X')\n",
    "    if x_second_index == -1:\n",
    "        return 1, input[0: x_index], second_part\n",
    "    return input[0: x_index], second_part[0: x_second_index], second_part[x_second_index + 1: len(second_part)]\n",
    "\n",
    "\n",
    "unit_map = {\n",
    "    'KG': 1000,\n",
    "    'ST': 6350,\n",
    "    'P': 454,\n",
    "    'M': 100,\n",
    "    'L': 1000,\n",
    "    'G': 1,\n",
    "    'CM': 1,\n",
    "    'ML': 1,\n",
    "}\n",
    "\n",
    "\n",
    "def unit_converter(row):\n",
    "    return row['content_3'] * unit_map[row['unit']]\n",
    "\n",
    "\n",
    "def prepare_dataset():\n",
    "    output = Path('data/unit_fixed.pkl')\n",
    "    if not output.is_file():\n",
    "        # example of using merge_data function for train dataset\n",
    "        mrg = merge_data('data/train.csv', 'data/items.csv', 'data/train_merged.pkl')\n",
    "\n",
    "        # add count feature (revenue/price)\n",
    "        mrg['count'] = mrg.revenue / mrg.price\n",
    "\n",
    "        # uppercase all pharmForm values\n",
    "        mrg['pharmForm'] = mrg['pharmForm'].str.upper()\n",
    "        # extract pharmForm values as binary feature and adding them to dataset\n",
    "        mrg = pd.concat([mrg, pd.get_dummies(mrg['pharmForm'])], axis=1)\n",
    "        mrg = mrg.drop('pharmForm', 1)\n",
    "\n",
    "        # split count of packs and amount of each to separate columns\n",
    "        extracted_numbers = mrg['content'].apply(extract_numbers_from_content)\n",
    "        extracted_numbers = pd.DataFrame(extracted_numbers.tolist(), columns=['content_1', 'content_2', 'content_3'],\n",
    "                                         index=extracted_numbers.index)\n",
    "        extracted_numbers['content_1'] = pd.to_numeric(extracted_numbers['content_1'])\n",
    "        extracted_numbers['content_2'] = pd.to_numeric(extracted_numbers['content_2'])\n",
    "        extracted_numbers['content_3'] = pd.to_numeric(extracted_numbers['content_3'])\n",
    "        mrg = pd.concat([mrg, extracted_numbers], axis=1)\n",
    "        mrg = mrg.drop('content', 1)\n",
    "\n",
    "        mrg['content_3'] = mrg.apply(unit_converter, axis=1)\n",
    "        mapping = {'KG': 'G', 'ST': 'G', 'P': 'G', 'L': 'ML', 'M': 'CM'}\n",
    "        mrg = mrg.replace({'unit': mapping})\n",
    "        pd.to_pickle(mrg, '../data/unit_fixed.pkl')\n",
    "        print('units converted')\n",
    "    else:\n",
    "        mrg = pd.read_pickle('data/unit_fixed.pkl')\n",
    "\n",
    "    # fill campaignIndex with D and then get dummy binary values of each category index\n",
    "    # mrg['campaignIndex'].fillna('D', inplace=True)\n",
    "    # mrg = pd.concat([mrg, pd.get_dummies(mrg['campaignIndex'])], axis=1)\n",
    "\n",
    "    # mrg = pd.concat([mrg, pd.get_dummies(mrg['group'])], axis=1)\n",
    "    return mrg\n",
    "\n",
    "\n",
    "def predict_competitor(all_data):\n",
    "    train = all_data[pd.notnull(all_data['competitorPrice'])]\n",
    "    kf = KFold(n_splits=10)\n",
    "    estimator = XGBRegressor()\n",
    "    x = train.drop('competitorPrice', 1)\n",
    "    y = train['competitorPri1ce']\n",
    "    scores = cross_val_score(estimator,\n",
    "                             x,\n",
    "                             y,\n",
    "                             cv=kf,\n",
    "                             scoring=make_scorer(mean_squared_error))\n",
    "    print(scores)\n",
    "\n",
    "\n",
    "data = prepare_dataset()\n",
    "# from scipy.stats import pearsonr\n",
    "#\n",
    "# print(data['category'].fillna(0))\n",
    "# print(pearsonr(data['category'].fillna(0), data['count']))\n",
    "\n",
    "\n",
    "# TODO handle features: category, group, competitor\n",
    "# TODO Random Forrest on server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "campaign_missing = data[pd.isnull(data['campaignIndex'])]['lineID']\n",
    "adFlag_missing = data[data['adFlag'] == 0]['lineID']\n",
    "# print(campaign_missing)\n",
    "# print(data['adFlag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(campaign_missing))\n",
    "print(len(adFlag_missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1651555\n"
     ]
    }
   ],
   "source": [
    "intersections = pd.Series(\n",
    "    list(set(campaign_missing).intersection(\n",
    "        set(adFlag_missing))))\n",
    "print(len(intersections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1651555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1651555\n0          NaN\n1            C\n2          NaN\n3          NaN\n4          NaN\n5          NaN\n6          NaN\n7          NaN\n8          NaN\n9          NaN\n10           C\n11         NaN\n12         NaN\n13         NaN\n14         NaN\n15           A\n16           B\n17         NaN\n18         NaN\n19         NaN\n20         NaN\n21         NaN\n22         NaN\n23         NaN\n24           B\n25         NaN\n26         NaN\n27         NaN\n28         NaN\n29         NaN\n          ... \n2755973    NaN\n2755974    NaN\n2755975    NaN\n2755976    NaN\n2755977    NaN\n2755978    NaN\n2755979    NaN\n2755980    NaN\n2755981    NaN\n2755982    NaN\n2755983    NaN\n2755984    NaN\n2755985    NaN\n2755986    NaN\n2755987      B\n2755988    NaN\n2755989    NaN\n2755990    NaN\n2755991      B\n2755992    NaN\n2755993    NaN\n2755994    NaN\n2755995    NaN\n2755996    NaN\n2755997    NaN\n2755998    NaN\n2755999    NaN\n2756000    NaN\n2756001      A\n2756002      A\nName: campaignIndex, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print(intersections)\n",
    "# These are lineIDs with missing campaignIndex and adFlag=0\n",
    "print(len(intersections))\n",
    "ind = data.lineID.isin(intersections.tolist())\n",
    "print(len(data[ind]['campaignIndex']))\n",
    "print(data['campaignIndex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            D\n1            C\n2            D\n3          NaN\n4            D\n5            D\n6          NaN\n7            D\n8            D\n9          NaN\n10           C\n11         NaN\n12           D\n13           D\n14           D\n15           A\n16           B\n17           D\n18           D\n19           D\n20           D\n21           D\n22           D\n23           D\n24           B\n25           D\n26           D\n27           D\n28         NaN\n29           D\n          ... \n2755973      D\n2755974      D\n2755975      D\n2755976      D\n2755977      D\n2755978    NaN\n2755979      D\n2755980      D\n2755981      D\n2755982      D\n2755983      D\n2755984      D\n2755985    NaN\n2755986      D\n2755987      B\n2755988      D\n2755989      D\n2755990      D\n2755991      B\n2755992      D\n2755993      D\n2755994      D\n2755995      D\n2755996      D\n2755997    NaN\n2755998      D\n2755999      D\n2756000      D\n2756001      A\n2756002      A\nName: campaignIndex, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# To be filled with D\n",
    "data['campaignIndex'].\\\n",
    "    fillna(data[ind]['campaignIndex'].fillna('D'), inplace=True)\n",
    "print(data['campaignIndex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          lineID  day    pid  adFlag  availability  competitorPrice  click  \\\n0              1    1   6570       0             2            14.60      1   \n1              2    1  14922       1             1             8.57      0   \n2              3    1  16382       0             1            14.77      0   \n4              5    1   3394       0             1             4.39      0   \n5              6    1   3661       0             1            13.66      0   \n7              8    1  16963       0             1             8.78      1   \n8              9    1  14560       0             1            10.84      1   \n10            11    1  14921       1             1             3.95      0   \n12            13    1  14010       0             1            19.79      0   \n13            14    1  18558       0             1            18.08      0   \n14            15    1  21983       0             1              NaN      0   \n15            16    1   5567       1             1            23.41      1   \n16            17    1  13156       0             1             4.12      0   \n17            18    1   5355       0             2             5.95      0   \n18            19    1   3254       0             1             1.08      0   \n19            20    1  13607       0             1            14.78      1   \n20            21    1  12563       0             1            30.68      0   \n21            22    1  19205       0             1             3.87      0   \n22            23    1  18345       0             1             9.34      1   \n23            24    1  12512       0             1             4.27      1   \n24            25    1   2655       1             1            13.74      0   \n25            26    1   3121       0             1             8.32      0   \n26            27    1   8780       0             1             5.82      0   \n27            28    1   9459       0             1             3.26      0   \n29            30    1  13608       0             1            11.37      0   \n30            31    1    768       0             1             3.45      0   \n31            32    1  15593       0             2            20.72      1   \n32            33    1  16644       0             2            18.17      1   \n34            35    1   6833       0             1             9.23      0   \n35            36    1   2655       1             1            13.74      0   \n...          ...  ...    ...     ...           ...              ...    ...   \n2755970  2755971   92   2655       1             1            13.74      0   \n2755971  2755972   92   5665       0             4            32.99      1   \n2755972  2755973   92   8744       0             1            14.78      1   \n2755973  2755974   92   2846       0             2             6.70      1   \n2755974  2755975   92  14974       0             1            11.57      0   \n2755975  2755976   92  20824       0             1              NaN      1   \n2755976  2755977   92  17316       0             1            29.29      1   \n2755977  2755978   92  13432       0             1             6.03      1   \n2755979  2755980   92    894       0             1            44.99      1   \n2755980  2755981   92  20233       0             2            47.18      1   \n2755981  2755982   92   6144       0             1             6.56      0   \n2755982  2755983   92  20135       0             1            18.64      1   \n2755983  2755984   92   1958       0             1             9.67      0   \n2755984  2755985   92   6874       0             1             8.79      1   \n2755986  2755987   92   4957       0             1              NaN      1   \n2755987  2755988   92   2655       1             1            13.74      0   \n2755988  2755989   92  17530       0             1             2.96      1   \n2755989  2755990   92  20720       0             1             4.98      1   \n2755990  2755991   92  20376       0             1            11.76      1   \n2755991  2755992   92  20613       0             1             8.78      1   \n2755992  2755993   92  15739       0             1            13.85      1   \n2755993  2755994   92  18007       0             1             5.68      1   \n2755994  2755995   92   8096       0             1             2.86      1   \n2755995  2755996   92   5691       0             1            28.91      0   \n2755996  2755997   92  17611       0             1             2.52      0   \n2755998  2755999   92  15767       0             1            22.41      1   \n2755999  2756000   92   2087       0             1            36.87      1   \n2756000  2756001   92   2944       0             1             4.71      1   \n2756001  2756002   92   3853       1             1             6.59      0   \n2756002  2756003   92   3854       1             1             8.78      1   \n\n         basket  order  price    ...      XNC  XPK XTC ZBU  ZCR  ZGE  ZPA  \\\n0             0      0  16.89    ...        0    0   0   0    0    0    0   \n1             1      0   8.75    ...        0    0   0   0    0    0    0   \n2             1      0  16.06    ...        0    0   0   0    0    0    0   \n4             0      1   4.14    ...        0    0   0   0    0    0    0   \n5             0      1  10.03    ...        0    0   0   0    0    0    0   \n7             0      0   8.75    ...        0    0   0   0    0    0    0   \n8             0      0  12.04    ...        0    0   0   0    0    0    0   \n10            1      0   4.35    ...        0    0   0   0    0    0    0   \n12            0      1  19.71    ...        0    0   0   0    0    0    0   \n13            0      1  19.15    ...        0    0   0   0    0    0    0   \n14            0      1  54.95    ...        0    0   0   0    0    0    0   \n15            0      0  26.35    ...        0    0   0   0    0    0    0   \n16            1      0   5.33    ...        0    0   0   0    0    0    0   \n17            1      0   8.09    ...        0    0   0   0    0    0    0   \n18            1      0   1.30    ...        0    0   0   0    0    0    0   \n19            0      0  11.20    ...        0    0   0   0    0    0    0   \n20            1      0  30.75    ...        0    0   0   0    0    0    0   \n21            1      0   3.05    ...        0    0   0   0    0    0    0   \n22            0      0  13.18    ...        0    0   0   0    0    0    0   \n23            0      0   3.58    ...        0    0   0   0    0    0    0   \n24            1      0  15.35    ...        0    0   0   0    0    0    0   \n25            0      1   9.04    ...        0    0   0   0    0    0    0   \n26            0      1   6.00    ...        0    0   0   0    0    0    0   \n27            0      1   4.02    ...        0    0   0   0    0    0    0   \n29            1      0   8.87    ...        0    0   0   0    0    0    0   \n30            1      0   3.25    ...        0    0   0   0    0    0    0   \n31            0      0  20.30    ...        0    0   0   0    0    0    0   \n32            0      0  17.89    ...        0    0   0   0    0    0    0   \n34            1      0   9.62    ...        0    0   0   0    0    0    0   \n35            1      0  15.35    ...        0    0   0   0    0    0    0   \n...         ...    ...    ...    ...      ...  ...  ..  ..  ...  ...  ...   \n2755970       1      0  15.35    ...        0    0   0   0    0    0    0   \n2755971       0      0  30.23    ...        0    0   0   0    0    0    0   \n2755972       0      0   6.55    ...        0    0   0   0    0    0    0   \n2755973       0      0   8.67    ...        0    0   0   0    0    0    0   \n2755974       0      1  10.92    ...        0    0   0   0    0    0    0   \n2755975       0      0  10.95    ...        0    0   0   0    0    0    0   \n2755976       0      0  35.15    ...        0    0   0   0    0    0    0   \n2755977       0      0   6.55    ...        0    0   0   0    0    0    0   \n2755979       0      0  38.45    ...        0    0   0   0    0    0    0   \n2755980       0      0  49.80    ...        0    0   0   0    0    0    0   \n2755981       1      0   8.25    ...        0    0   0   0    0    0    0   \n2755982       0      0  19.75    ...        0    0   0   0    0    0    0   \n2755983       1      0  10.39    ...        0    0   0   0    0    0    0   \n2755984       0      0   8.20    ...        0    0   0   0    0    0    0   \n2755986       0      0   5.70    ...        0    0   0   0    0    0    0   \n2755987       1      0  15.35    ...        0    0   0   0    0    0    0   \n2755988       0      0   3.03    ...        0    0   0   0    0    0    0   \n2755989       0      0   7.21    ...        0    0   0   0    0    0    0   \n2755990       0      0  12.52    ...        0    0   0   0    0    0    0   \n2755991       0      0   8.75    ...        0    0   0   0    0    0    0   \n2755992       0      0  12.04    ...        0    0   0   0    0    0    0   \n2755993       0      0   6.74    ...        0    0   0   0    0    0    0   \n2755994       0      0   3.25    ...        0    0   0   0    0    0    0   \n2755995       0      1  33.39    ...        0    0   0   0    0    0    0   \n2755996       0      1   3.12    ...        0    0   0   0    0    0    0   \n2755998       0      0  18.64    ...        0    0   0   0    0    0    0   \n2755999       0      0  43.18    ...        0    0   0   0    0    0    0   \n2756000       0      0   5.59    ...        0    0   0   0    0    0    0   \n2756001       1      0   6.33    ...        0    0   0   0    0    0    0   \n2756002       0      0   9.85    ...        0    0   0   0    0    0    0   \n\n        content_1  content_2  content_3  \n0               1          1       50.0  \n1               1          1   317500.0  \n2               1          2       50.0  \n4               1         25    12700.0  \n5               1          1     1000.0  \n7               1          1      100.0  \n8               1          1       50.0  \n10              1          1   127000.0  \n12              1          1     6350.0  \n13              1          1        3.0  \n14              1          1      454.0  \n15              1          1    38100.0  \n16              1          1   127000.0  \n17              1          1      100.0  \n18              1          1    63500.0  \n19              1          1   190500.0  \n20              1          1   635000.0  \n21              1          1       50.0  \n22              1          1       12.0  \n23              1          1      500.0  \n24              1          1       50.0  \n25              1          1       20.0  \n26              1          1      400.0  \n27              1          1        6.0  \n29              1          1   190500.0  \n30              1          1   508000.0  \n31              1          1     6350.0  \n32              1          1       50.0  \n34              1          1       75.0  \n35              1          1       50.0  \n...           ...        ...        ...  \n2755970         1          1       50.0  \n2755971         1          1   381000.0  \n2755972         1          4      200.0  \n2755973         1          1      200.0  \n2755974         1          1     1000.0  \n2755975         1          1   381000.0  \n2755976         1          1        6.6  \n2755977         1          1       20.0  \n2755979         6          4      200.0  \n2755980         1        120        0.3  \n2755981         1          1       40.0  \n2755982         1          1       50.0  \n2755983         1          1       15.0  \n2755984         1          1        5.0  \n2755986         1          1      150.0  \n2755987         1          1       50.0  \n2755988         1          1    76200.0  \n2755989         1          1       10.0  \n2755990         1          1   101600.0  \n2755991         1          1   152400.0  \n2755992         1          1     6350.0  \n2755993         1          1   254000.0  \n2755994         1          1      150.0  \n2755995         1          1   635000.0  \n2755996         1          1   127000.0  \n2755998         1          1       15.0  \n2755999         1          1  1270000.0  \n2756000         1          1   158750.0  \n2756001         1          1       50.0  \n2756002         1          1      100.0  \n\n[2119590 rows x 206 columns]\n"
     ]
    }
   ],
   "source": [
    "# To be filled with similar product campaign Index\n",
    "print()\n",
    "# print(data[['pid', 'manufacturer']])\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "train_data = data[pd.notnull(data['campaignIndex'])]\n",
    "lr.fit(train_data[['pid', 'manufacturer']], train_data['campaignIndex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}