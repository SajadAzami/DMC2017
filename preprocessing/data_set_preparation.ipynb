{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from preprocessing.data_preparation import read_data\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# merge items and train data to a dataFrame\n",
    "def merge_data(input_path, items_path, output_path):\n",
    "    tdf = read_data(input_path)\n",
    "    idf = read_data(items_path)\n",
    "    print('data read successfully!')\n",
    "    output = Path(output_path)\n",
    "    if not output.is_file():\n",
    "        train_merged = tdf.copy()\n",
    "        train_merged = train_merged.merge(tdf.merge(idf, how='left', on='pid', sort=False))\n",
    "        pd.to_pickle(train_merged, output_path)\n",
    "        return train_merged\n",
    "    else:\n",
    "        return pd.read_pickle(output_path)\n",
    "\n",
    "\n",
    "def extract_numbers_from_content(input):\n",
    "    x_index = input.find('X')\n",
    "    if input == 'L   125':\n",
    "        return 1, 1, 125\n",
    "    if x_index == -1:\n",
    "        if input == 'PAK':\n",
    "            return 1, 1, 1\n",
    "        return 1, 1, input\n",
    "    second_part = input[x_index + 1: len(input)]\n",
    "    x_second_index = second_part.find('X')\n",
    "    if x_second_index == -1:\n",
    "        return 1, input[0: x_index], second_part\n",
    "    return input[0: x_index], second_part[0: x_second_index], second_part[x_second_index + 1: len(second_part)]\n",
    "\n",
    "\n",
    "unit_map = {\n",
    "    'KG': 1000,\n",
    "    'ST': 6350,\n",
    "    'P': 454,\n",
    "    'M': 100,\n",
    "    'L': 1000,\n",
    "    'G': 1,\n",
    "    'CM': 1,\n",
    "    'ML': 1,\n",
    "}\n",
    "\n",
    "\n",
    "def unit_converter(row):\n",
    "    return row['content_3'] * unit_map[row['unit']]\n",
    "\n",
    "\n",
    "def prepare_dataset():\n",
    "    output = Path('data/unit_fixed.pkl')\n",
    "    if not output.is_file():\n",
    "        # example of using merge_data function for train dataset\n",
    "        mrg = merge_data('data/train.csv', 'data/items.csv', 'data/train_merged.pkl')\n",
    "\n",
    "        # add count feature (revenue/price)\n",
    "        mrg['count'] = mrg.revenue / mrg.price\n",
    "\n",
    "        # uppercase all pharmForm values\n",
    "        mrg['pharmForm'] = mrg['pharmForm'].str.upper()\n",
    "        # extract pharmForm values as binary feature and adding them to dataset\n",
    "        mrg = pd.concat([mrg, pd.get_dummies(mrg['pharmForm'])], axis=1)\n",
    "        mrg = mrg.drop('pharmForm', 1)\n",
    "\n",
    "        # split count of packs and amount of each to separate columns\n",
    "        extracted_numbers = mrg['content'].apply(extract_numbers_from_content)\n",
    "        extracted_numbers = pd.DataFrame(extracted_numbers.tolist(), columns=['content_1', 'content_2', 'content_3'],\n",
    "                                         index=extracted_numbers.index)\n",
    "        extracted_numbers['content_1'] = pd.to_numeric(extracted_numbers['content_1'])\n",
    "        extracted_numbers['content_2'] = pd.to_numeric(extracted_numbers['content_2'])\n",
    "        extracted_numbers['content_3'] = pd.to_numeric(extracted_numbers['content_3'])\n",
    "        mrg = pd.concat([mrg, extracted_numbers], axis=1)\n",
    "        mrg = mrg.drop('content', 1)\n",
    "\n",
    "        mrg['content_3'] = mrg.apply(unit_converter, axis=1)\n",
    "        mapping = {'KG': 'G', 'ST': 'G', 'P': 'G', 'L': 'ML', 'M': 'CM'}\n",
    "        mrg = mrg.replace({'unit': mapping})\n",
    "        pd.to_pickle(mrg, '../data/unit_fixed.pkl')\n",
    "        print('units converted')\n",
    "    else:\n",
    "        mrg = pd.read_pickle('data/unit_fixed.pkl')\n",
    "\n",
    "    # fill campaignIndex with D and then get dummy binary values of each category index\n",
    "    mrg['campaignIndex'].fillna('D', inplace=True)\n",
    "    mrg = pd.concat([mrg, pd.get_dummies(mrg['campaignIndex'])], axis=1)\n",
    "\n",
    "    # mrg = pd.concat([mrg, pd.get_dummies(mrg['group'])], axis=1)\n",
    "    return mrg\n",
    "\n",
    "\n",
    "def predict_competitor(all_data):\n",
    "    train = all_data[pd.notnull(all_data['competitorPrice'])]\n",
    "    kf = KFold(n_splits=10)\n",
    "    estimator = XGBRegressor()\n",
    "    x = train.drop('competitorPrice', 1)\n",
    "    y = train['competitorPri1ce']\n",
    "    scores = cross_val_score(estimator,\n",
    "                             x,\n",
    "                             y,\n",
    "                             cv=kf,\n",
    "                             scoring=make_scorer(mean_squared_error))\n",
    "    print(scores)\n",
    "\n",
    "\n",
    "data = prepare_dataset()\n",
    "# from scipy.stats import pearsonr\n",
    "#\n",
    "# print(data['category'].fillna(0))\n",
    "# print(pearsonr(data['category'].fillna(0), data['count']))\n",
    "\n",
    "\n",
    "# TODO handle features: category, group, competitor\n",
    "# TODO Random Forrest on server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                1\n2                3\n3                4\n4                5\n5                6\n6                7\n7                8\n8                9\n9               10\n11              12\n12              13\n13              14\n14              15\n17              18\n18              19\n19              20\n20              21\n21              22\n22              23\n23              24\n25              26\n26              27\n27              28\n28              29\n29              30\n30              31\n31              32\n32              33\n33              34\n36              37\n            ...   \n2755968    2755969\n2755969    2755970\n2755971    2755972\n2755972    2755973\n2755973    2755974\n2755974    2755975\n2755975    2755976\n2755976    2755977\n2755977    2755978\n2755978    2755979\n2755979    2755980\n2755980    2755981\n2755981    2755982\n2755982    2755983\n2755983    2755984\n2755984    2755985\n2755985    2755986\n2755986    2755987\n2755988    2755989\n2755989    2755990\n2755990    2755991\n2755992    2755993\n2755993    2755994\n2755994    2755995\n2755995    2755996\n2755996    2755997\n2755997    2755998\n2755998    2755999\n2755999    2756000\n2756000    2756001\nName: lineID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from preprocessing.data_preparation import get_missing_count\n",
    "\n",
    "campaign_missing = data[pd.isnull(data['campaignIndex'])]['lineID']\n",
    "adFlag_missing = data[data['adFlag'] == 0]['lineID']\n",
    "# print(campaign_missing)\n",
    "# print(data['adFlag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1880176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2287968\n"
     ]
    }
   ],
   "source": [
    "print(len(data[data['adFlag'] == 0]))\n",
    "print(get_missing_count(data['campaignIndex']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections = pd.Series(\n",
    "    list(set(campaign_missing).intersection(\n",
    "        set(adFlag_missing))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be filled with D\n",
    "print(intersections.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636413\n"
     ]
    }
   ],
   "source": [
    "# To be filled with similar product campaign Index\n",
    "print(len(set(campaign_missing) - set(intersections)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}